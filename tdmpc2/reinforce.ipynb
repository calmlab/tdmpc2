{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.environ['MUJOCO_GL'] = 'egl'\n",
    "os.environ['LAZY_LEGACY_OP'] = '0'\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import torch\n",
    "\n",
    "import hydra\n",
    "from termcolor import colored\n",
    "\n",
    "from common.parser import parse_cfg\n",
    "from common.seed import set_seed\n",
    "from common.buffer import Buffer\n",
    "from envs import make_env\n",
    "from dialectic import DialecticMPC, DialecticImitation\n",
    "from trainer.offline_trainer import OfflineTrainer\n",
    "from trainer.online_trainer import OnlineTrainer\n",
    "from common.logger import Logger\n",
    "\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import yaml\n",
    "\n",
    "def read_yaml_to_dict(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r') as file:\n",
    "            yaml_data = yaml.safe_load(file)\n",
    "        return yaml_data\n",
    "    except FileNotFoundError:\n",
    "        print(f\"파일을 찾을 수 없습니다: {file_path}\")\n",
    "        return None\n",
    "    except yaml.YAMLError as e:\n",
    "        print(f\"YAML 파싱 오류: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YAML 내용:\n",
      "{'defaults': [{'override hydra/launcher': 'submitit_local'}], 'task': 'walker-walk', 'obs': 'state', 'checkpoint': '???', 'eval_episodes': 10, 'eval_freq': 5000, 'device': 'cuda', 'steps': 10000000, 'batch_size': 256, 'reward_coef': 0.1, 'value_coef': 0.1, 'consistency_coef': 20, 'rho': 0.5, 'lr': '3e-4', 'enc_lr_scale': 0.3, 'grad_clip_norm': 20, 'tau': 0.01, 'discount_denom': 5, 'discount_min': 0.95, 'discount_max': 0.995, 'buffer_size': 1000000, 'exp_name': 'default', 'data_dir': '???', 'mpc': True, 'iterations': 6, 'num_samples': 512, 'num_elites': 64, 'num_pi_trajs': 24, 'horizon': 3, 'min_std': 0.05, 'max_std': 2, 'temperature': 0.5, 'log_std_min': -10, 'log_std_max': 2, 'entropy_coef': '1e-4', 'num_bins': 101, 'vmin': -10, 'vmax': 10, 'model_size': '???', 'num_enc_layers': 2, 'enc_dim': 256, 'num_channels': 32, 'mlp_dim': 512, 'latent_dim': 512, 'task_dim': 96, 'num_q': 5, 'dropout': 0.01, 'simnorm_dim': 8, 'wandb_project': 'dialectic-mujoco', 'wandb_entity': 'calmlab', 'wandb_silent': False, 'disable_wandb': True, 'save_csv': True, 'save_video': True, 'save_agent': True, 'seed': 1, 'work_dir': '???', 'task_title': '???', 'multitask': '???', 'tasks': '???', 'obs_shape': '???', 'action_dim': '???', 'episode_length': '???', 'obs_shapes': '???', 'action_dims': '???', 'episode_lengths': '???', 'seed_steps': '???', 'bin_size': '???', 'obs_dim_l': '???', 'obs_dim_r': '???', 'action_dim_l': '???', 'action_dim_r': '???'}\n"
     ]
    }
   ],
   "source": [
    "# 사용 예시\n",
    "file_path = 'dialectic_config.yaml'\n",
    "result = read_yaml_to_dict(file_path)\n",
    "\n",
    "if result:\n",
    "    print(\"YAML 내용:\")\n",
    "    print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from omegaconf import OmegaConf\n",
    "cfg = OmegaConf.load('dialectic_config.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/pipaek/project/tdmpc2/logs/walker-walk/1/default')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "work_dir = Path('/home/pipaek/project/tdmpc2') / 'logs' / cfg.task / str(cfg.seed) / cfg.exp_name\n",
    "\n",
    "cfg.work_dir = work_dir\n",
    "work_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from common import MODEL_SIZE, TASK_SET\n",
    "\n",
    "def myparse_cfg(cfg: OmegaConf) -> OmegaConf:\n",
    "\t\"\"\"\n",
    "\tParses a Hydra config. Mostly for convenience.\n",
    "\t\"\"\"\n",
    "\n",
    "\t# Logic\n",
    "\tfor k in cfg.keys():\n",
    "\t\ttry:\n",
    "\t\t\tv = cfg[k]\n",
    "\t\t\tif v == None:\n",
    "\t\t\t\tv = True\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\n",
    "\t# Algebraic expressions\n",
    "\tfor k in cfg.keys():\n",
    "\t\ttry:\n",
    "\t\t\tv = cfg[k]\n",
    "\t\t\tif isinstance(v, str):\n",
    "\t\t\t\tmatch = re.match(r\"(\\d+)([+\\-*/])(\\d+)\", v)\n",
    "\t\t\t\tif match:\n",
    "\t\t\t\t\tcfg[k] = eval(match.group(1) + match.group(2) + match.group(3))\n",
    "\t\t\t\t\tif isinstance(cfg[k], float) and cfg[k].is_integer():\n",
    "\t\t\t\t\t\tcfg[k] = int(cfg[k])\n",
    "\t\texcept:\n",
    "\t\t\tpass\n",
    "\n",
    "\t# Convenience\n",
    "\tcfg.task_title = cfg.task.replace(\"-\", \" \").title()\n",
    "\tcfg.bin_size = (cfg.vmax - cfg.vmin) / (cfg.num_bins-1) # Bin size for discrete regression\n",
    "\n",
    "\t# Model size\n",
    "\tif cfg.get('model_size', None) is not None:\n",
    "\t\tassert cfg.model_size in MODEL_SIZE.keys(), \\\n",
    "\t\t\tf'Invalid model size {cfg.model_size}. Must be one of {list(MODEL_SIZE.keys())}'\n",
    "\t\tfor k, v in MODEL_SIZE[cfg.model_size].items():\n",
    "\t\t\tcfg[k] = v\n",
    "\t\tif cfg.task == 'mt30' and cfg.model_size == 19:\n",
    "\t\t\tcfg.latent_dim = 512 # This checkpoint is slightly smaller\n",
    "\n",
    "\t# Multi-task\n",
    "\tcfg.multitask = cfg.task in TASK_SET.keys()\n",
    "\tif cfg.multitask:\n",
    "\t\tcfg.task_title = cfg.task.upper()\n",
    "\t\t# Account for slight inconsistency in task_dim for the mt30 experiments\n",
    "\t\tcfg.task_dim = 96 if cfg.task == 'mt80' or cfg.model_size in {1, 317} else 64\n",
    "\telse:\n",
    "\t\tcfg.task_dim = 0\n",
    "\tcfg.tasks = TASK_SET.get(cfg.task, [cfg.task])\n",
    "\n",
    "\treturn cfg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = myparse_cfg(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(cfg.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[34m### Logger Init.\u001b[0m\n",
      "------------------------------------\n",
      "  \u001b[1m\u001b[32mTask:          \u001b[0m Walker Walk\n",
      "  \u001b[1m\u001b[32mSteps:         \u001b[0m 10,000,000\n",
      "  \u001b[1m\u001b[32mObservations:  \u001b[0m [24]\n",
      "  \u001b[1m\u001b[32mActions:       \u001b[0m 6\n",
      "  \u001b[1m\u001b[32mExperiment:    \u001b[0m default\n",
      "------------------------------------\n",
      "\u001b[1m\u001b[34mWandb disabled.\u001b[0m\n",
      "Architecture: DualModel(\n",
      "  (_brain_l): Sequential(\n",
      "    (0): NormedLinear(in_features=18, out_features=512, bias=True, act=Mish)\n",
      "    (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)\n",
      "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      "  (_brain_r): Sequential(\n",
      "    (0): NormedLinear(in_features=18, out_features=512, bias=True, act=Mish)\n",
      "    (1): NormedLinear(in_features=512, out_features=512, bias=True, act=Mish)\n",
      "    (2): Linear(in_features=512, out_features=6, bias=True)\n",
      "  )\n",
      ")\n",
      "Learnable parameters: 555,020\n"
     ]
    }
   ],
   "source": [
    "from trainer.online_trainer import OnlineTrainer, OnlineDialecticTrainer\n",
    "\n",
    "trainer = OnlineDialecticTrainer(\n",
    "\t\tcfg=cfg,\n",
    "\t\tenv=make_env(cfg),\n",
    "\t\tagent=DialecticImitation(cfg),\n",
    "\t\tbuffer_l=Buffer(cfg),\n",
    "        buffer_r=Buffer(cfg),\n",
    "\t\tlogger=Logger(cfg),\n",
    "\t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_metrics, done, eval_next = {}, True, True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "_step = 0\n",
    "_ep_idx = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = self.env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorDict(\n",
       "    fields={\n",
       "        action: Tensor(shape=torch.Size([1, 6]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        obs: Tensor(shape=torch.Size([1, 24]), device=cpu, dtype=torch.float32, is_shared=False),\n",
       "        reward: Tensor(shape=torch.Size([1]), device=cpu, dtype=torch.float32, is_shared=False)},\n",
       "    batch_size=torch.Size([1]),\n",
       "    device=None,\n",
       "    is_shared=False)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "td = self.to_td(obs)\n",
    "td"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([-0.7661, -0.2494, -0.3876,  0.2716, -0.5663,  0.6794])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action, is_act_left = self.agent.rand_act(self.env)\n",
    "action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self.agent.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for *=: 'float' and 'NoneType'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[68], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_tds_l \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m500\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m     td \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_td(obs, action, reward)\n\u001b[1;32m      5\u001b[0m     action, is_act_left \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39magent\u001b[38;5;241m.\u001b[39mrand_act(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv)\n",
      "File \u001b[0;32m/media/hdd1/pipaek/project/tdmpc2/tdmpc2/envs/wrappers/tensor.py:37\u001b[0m, in \u001b[0;36mTensorWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m---> 37\u001b[0m \tobs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     38\u001b[0m \tinfo \u001b[38;5;241m=\u001b[39m defaultdict(\u001b[38;5;28mfloat\u001b[39m, info)\n\u001b[1;32m     39\u001b[0m \tinfo[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(info[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuccess\u001b[39m\u001b[38;5;124m'\u001b[39m])\n",
      "File \u001b[0;32m/media/hdd1/pipaek/project/tdmpc2/tdmpc2/envs/dmcontrol.py:173\u001b[0m, in \u001b[0;36mTimeStepToGymWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    171\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    172\u001b[0m \t\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 173\u001b[0m \ttime_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    174\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_obs_to_array(time_step\u001b[38;5;241m.\u001b[39mobservation), time_step\u001b[38;5;241m.\u001b[39mreward, time_step\u001b[38;5;241m.\u001b[39mlast() \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mt \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_episode_steps, defaultdict(\u001b[38;5;28mfloat\u001b[39m)\n",
      "File \u001b[0;32m/media/hdd1/pipaek/project/tdmpc2/tdmpc2/envs/dmcontrol.py:97\u001b[0m, in \u001b[0;36mExtendedTimeStepWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m---> 97\u001b[0m \ttime_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     98\u001b[0m \t\u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_augment_time_step(time_step, action)\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/site-packages/dm_control/suite/wrappers/action_scale.py:91\u001b[0m, in \u001b[0;36mWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m---> 91\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/hdd1/pipaek/project/tdmpc2/tdmpc2/envs/dmcontrol.py:42\u001b[0m, in \u001b[0;36mActionRepeatWrapper.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m     40\u001b[0m time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env\u001b[38;5;241m.\u001b[39mstep(action)\n\u001b[1;32m     41\u001b[0m reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m (time_step\u001b[38;5;241m.\u001b[39mreward \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m) \u001b[38;5;241m*\u001b[39m discount\n\u001b[0;32m---> 42\u001b[0m discount \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m=\u001b[39m time_step\u001b[38;5;241m.\u001b[39mdiscount\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m time_step\u001b[38;5;241m.\u001b[39mlast():\n\u001b[1;32m     44\u001b[0m \t\u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for *=: 'float' and 'NoneType'"
     ]
    }
   ],
   "source": [
    "self._tds_l = []\n",
    "for _ in range(200):\n",
    "    obs, reward, done, info = self.env.step(action)\n",
    "    td = self.to_td(obs, action, reward)\n",
    "    action, is_act_left = self.agent.rand_act(self.env)\n",
    "    self._tds_l.append(td)\n",
    "    # print(action, is_act_left, reward, done, info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(self._tds_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buffer capacity: 1,000,000\n",
      "Storage required: 0.13 GB\n",
      "Using CUDA memory for storage.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "self._ep_idx = self.buffer_l.add(torch.cat(self._tds_l))\n",
    "self._ep_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6410"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(self.buffer_l._buffer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "for _ in range(10):\n",
    "    self._tds_l = []\n",
    "    obs = self.env.reset()\n",
    "    for _ in range(1000):\n",
    "        obs, reward, done, info = self.env.step(action)\n",
    "        td = self.to_td(obs, action, reward)\n",
    "        action, is_act_left = self.agent.rand_act(self.env)\n",
    "        self._tds_l.append(td)\n",
    "        if done:\n",
    "            break\n",
    "    self._ep_idx = self.buffer_l.add(torch.cat(self._tds_l))\n",
    "    print(self._ep_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs, action, reward, task = self.buffer_l.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "The shape of the mask [0] at index 0 does not match the shape of the indexed tensor [1, 1] at index 0",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbuffer_l\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_buffer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/site-packages/torchrl/data/replay_buffers/replay_buffers.py:606\u001b[0m, in \u001b[0;36mReplayBuffer.sample\u001b[0;34m(self, batch_size, return_info)\u001b[0m\n\u001b[1;32m    604\u001b[0m             fut \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefetch_executor\u001b[38;5;241m.\u001b[39msubmit(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sample, batch_size)\n\u001b[1;32m    605\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_prefetch_queue\u001b[38;5;241m.\u001b[39mappend(fut)\n\u001b[0;32m--> 606\u001b[0m         ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prefetch_queue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpopleft\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    608\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m return_info:\n\u001b[1;32m    609\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/concurrent/futures/_base.py:440\u001b[0m, in \u001b[0;36mFuture.result\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    438\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m CancelledError()\n\u001b[1;32m    439\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_state \u001b[38;5;241m==\u001b[39m FINISHED:\n\u001b[0;32m--> 440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    441\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    442\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTimeoutError\u001b[39;00m()\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/concurrent/futures/_base.py:389\u001b[0m, in \u001b[0;36mFuture.__get_result\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__get_result\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    388\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception:\n\u001b[0;32m--> 389\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\n\u001b[1;32m    390\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    391\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/concurrent/futures/thread.py:52\u001b[0m, in \u001b[0;36m_WorkItem.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 52\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     54\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfuture\u001b[38;5;241m.\u001b[39mset_exception(exc)\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/site-packages/torchrl/data/replay_buffers/utils.py:50\u001b[0m, in \u001b[0;36mpin_memory_output.<locals>.decorated_fun\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorated_fun\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m---> 50\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[43mfun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     51\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m     52\u001b[0m         _tuple_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/site-packages/torchrl/data/replay_buffers/replay_buffers.py:540\u001b[0m, in \u001b[0;36mReplayBuffer._sample\u001b[0;34m(self, batch_size)\u001b[0m\n\u001b[1;32m    537\u001b[0m \u001b[38;5;129m@pin_memory_output\u001b[39m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_sample\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch_size: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m    539\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_replay_lock:\n\u001b[0;32m--> 540\u001b[0m         index, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sampler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_storage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    541\u001b[0m         info[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m index\n\u001b[1;32m    542\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_storage\u001b[38;5;241m.\u001b[39mget(index)\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/site-packages/torchrl/data/replay_buffers/samplers.py:1020\u001b[0m, in \u001b[0;36mSliceSampler.sample\u001b[0;34m(self, storage, batch_size)\u001b[0m\n\u001b[1;32m   1018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m, storage: Storage, batch_size: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[1;32m   1019\u001b[0m     \u001b[38;5;66;03m# pick up as many trajs as we need\u001b[39;00m\n\u001b[0;32m-> 1020\u001b[0m     start_idx, stop_idx, lengths \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_stop_and_length\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstorage\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1021\u001b[0m     \u001b[38;5;66;03m# we have to make sure that the number of dims of the storage\u001b[39;00m\n\u001b[1;32m   1022\u001b[0m     \u001b[38;5;66;03m# is the same as the stop/start signals since we will\u001b[39;00m\n\u001b[1;32m   1023\u001b[0m     \u001b[38;5;66;03m# use these to sample the storage\u001b[39;00m\n\u001b[1;32m   1024\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m start_idx\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m!=\u001b[39m storage\u001b[38;5;241m.\u001b[39mndim:\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/site-packages/torchrl/data/replay_buffers/samplers.py:965\u001b[0m, in \u001b[0;36mSliceSampler._get_stop_and_length\u001b[0;34m(self, storage, fallback)\u001b[0m\n\u001b[1;32m    961\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m    962\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    963\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not get a tensordict out of the storage, which is required for SliceSampler to compute the trajectories.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    964\u001b[0m         )\n\u001b[0;32m--> 965\u001b[0m vals \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_find_start_stop_traj\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    966\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrajectory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrajectory\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mat_capacity\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_is_full\u001b[49m\n\u001b[1;32m    967\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    968\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcache_values:\n\u001b[1;32m    969\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cache[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstop-and-length\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m vals\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/site-packages/torchrl/data/replay_buffers/samplers.py:886\u001b[0m, in \u001b[0;36mSliceSampler._find_start_stop_traj\u001b[0;34m(cls, trajectory, end, at_capacity)\u001b[0m\n\u001b[1;32m    882\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    883\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    884\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExpected the end-of-trajectory signal to be at least 1-dimensional.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    885\u001b[0m     )\n\u001b[0;32m--> 886\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_end_to_start_stop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlength\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlength\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mend\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/tdmpc2/lib/python3.9/site-packages/torchrl/data/replay_buffers/samplers.py:907\u001b[0m, in \u001b[0;36mSliceSampler._end_to_start_stop\u001b[0;34m(end, length)\u001b[0m\n\u001b[1;32m    905\u001b[0m m2 \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat([start_idx_mask, torch\u001b[38;5;241m.\u001b[39mzeros_like(start_idx_mask[:\u001b[38;5;241m1\u001b[39m])])\n\u001b[1;32m    906\u001b[0m start_idx_replace \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mempty_like(start_idx)\n\u001b[0;32m--> 907\u001b[0m start_idx_replace[m1] \u001b[38;5;241m=\u001b[39m \u001b[43mstart_idx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mm2\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    908\u001b[0m start_idx_replace[\u001b[38;5;241m~\u001b[39mm1] \u001b[38;5;241m=\u001b[39m start_idx[\u001b[38;5;241m~\u001b[39mm2]\n\u001b[1;32m    909\u001b[0m start_idx \u001b[38;5;241m=\u001b[39m start_idx_replace\n",
      "\u001b[0;31mIndexError\u001b[0m: The shape of the mask [0] at index 0 does not match the shape of the indexed tensor [1, 1] at index 0"
     ]
    }
   ],
   "source": [
    "self.buffer_l._buffer.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tdmpc2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
